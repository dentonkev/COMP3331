# 3331 Notes

### General Info

Lecturer: Wen Hu   
Course email: cs3331@cse.unsw.edu.au

- Labs: 20%
- Assignment: 20%
- Mid Term: 20% (Open-Book online at home)
- Final: 40% (Closed-Book online at uni)

## Protocol
Protocols define the **format**, **order** of **messages sent and received** among network entities, and **actions taken** on messages transmission, receipt.

## Internet strucutre

**Network edge**
- hosts: clients and servers
- servers often in data centers

<img src="./images/edge.png" width="300" height="auto">

**Access networks, physical media**
- wired, wireless communication links
 
<img src="./images/wired.png" width="300" height="auto">

**Network core**
- interconnected routers
- network of networks
  
<img src="./images/core.png" width="300" height="auto">

## Network Edge

### Digital subscriber line (DSL) (old)

- use existing telephone line to central office DSLAM 
  - data over DSL phone line goes to Internet
  - voice over DSL phone line goes to telephone net

<img src="./images/dsl.png" width="400" height="auto">

### Cable-based access

**Hybrid fiber coax (HFC):** up to 40-1200 Mbps downstream transmission rate, 30-100 Mbps upstream transmission rate

- network of cable, fiber attaches homes to ISP router 
  - homes share access network to cable headend

<img src="./images/cable.png" width="450" height="auto">

-  Fully optical fiber path all the way to the home (or premise or curb)

<img src="./images/nbn.png" width="500" height="auto">

### Home networks
<img src="./images/home.png" width="450" height="auto">

### LAN and WAN
**LAN (Local area network)**
- typically within or around building (~100 ft)
- 802.11b/g/n (WiFi): 11, 54, 450 Mbps transmission rate

**WAN (Wide area network)**
- provided by mobile, cellular network operator (10’s km)
- 10’sMbps
-  4G cellular networks (5G coming)

### Enterprise networks
- mix of wired, wireless link technologies, connecting a mix of switches and routers 

## Network Core
### Circuit Switching
End-end resources allocated to, reserved for “call” between source and destination

<img src="./images/cir.png" width="300" height="auto">
<img src="./images/c.png" width="400" height="auto">

### Packet Switching
Hosts break application-layer messages into **packets**

- Data is sent as chunks of formatted bits (**Packets**) 
- Packets consist of a **“header”** and **“payload”**
  - payload is the data being carried
  - header holds instructions to the network for how to handle packet
- Switches “**forward**” packets based on their headers

<img src="./images/packet.png" width="450" height="auto">

- store and forward packet switching

<img src="./images/p.png" width="450" height="auto">

## Timing Diagrams
<img src="./images/tim.png" width="450" height="auto">

- propogation time is 10s for each bit in the packet, however the propagation time overlaps with the transmission time of the next packet, so you only need to consider propogation time **once** for all 4 packets at the very end (32540 - 32550).
- transmission time for the entire packet is 0 - 8160 s

## Statistical multiplexing
Method of sharing communication channel among multiple users (senders) over a link. If one user does not use its share of the bandwidth, it is then free to be used by other users. Thus, senders **share the link bandwidth**, with no user having all of the link bandwidth allocated to it. 

<img src="./images/over.png" width="350" height="auto">
<img src="./images/over2.png" width="350" height="auto">
<img src="./images/over3.png" width="350" height="auto">
<img src="./images/over4.png" width="350" height="auto">
<img src="./images/over5.png" width="350" height="auto">

## Packet delay
Four sources of packet delay:
- propogation delay
- queueing delay
- transmission delay
- nodal processing

$L$ = packet length (bits)  
$R$ = link bandwidth (bits/sec)  
$a$ = packet arrival rate (packets/sec)

<img src="./images/del.png" width="450" height="auto">
<img src="./images/del2.png" width="450" height="auto">
<img src="./images/del3.png" width="450" height="auto">

## Delay Formulas (single packet)
$d_{processing}$ = given

$d_{queue}$ = given

$d_{transmission} = \frac{L}{R}$

$d_{propogation} = \frac{d}{s}$

<img src="./images/delay.png" width="300" height="auto">

$L$ = packet length (bits)  
$R$ = link bandwidth (bits/sec)  
$a$ = packet arrival rate (packets/sec)  
$s$ = propogation speed (m/sec)

## Bandwidth Delay Product Formula
$BDP$ measures the amount of data that can be in transit in the network at any given time. I

$BDP= R \times RTT$

$BDP$ = Bandwidth Delay Product (bits/bytes)
$R$ = bandwidth (bits/sec or bytes/sec)
$RTT$ = round trip time (sec)

## Packet loss
- queue (aka buffer) preceding link in buffer has finite capacity
- packet arriving to full queue dropped (aka lost)
- lost packet may be retransmitted by previous node,
source end system, or not at all

<img src="./images/ploss.png" width="450" height="auto">

## Throughput
- **Throughput**: rate (bits/time unit) at which bits are being sent from sender to receiver
- instantaneous: rate at given point in time 
- average: rate over longer period of time

<img src="./images/through.png" width="500" height="auto">

When $R_s < R_c$, average end-end throughput is $R_s$, since it is the bottleneck

## Internet protocol stack (OSI model)
- **Application**: supporting network applications 
  - FTP, MSTP, HTTP, email, WWW, Phone
- **Transport**: process-process data transfer
  - TCP, UDP
- **Network**: routing of datagrams from source to destination
  - IP, routing protocols
- **Link**: data transfer between neighbouring network elements
  - Ethernet, 802.11 (WiFi), PPP
- **Physical**: bits on the wire
  - copper, fibre, radio

<img src="./images/ips.png" width="200" height="auto">

Each layer depends on layer below and supports layer above (indepdendent of others)

## Internet Layered Architecture
<img src="./images/ila.png" width="500" height="auto">
<img src="./images/encap.png" width="500" height="auto">

# Application Layer (Principles, Web, Email)

## Client-server paradigm
**Server**:
- always-on host
- permanent IP address
- often in data centers
  
**Clients**:
- contact, communicate with server
- may be intermittently connected
- may have dynamic IP addresses
- do not communicate directly with each other
- examples: HTTP, IMAP, FTP

## Processes communicating
**Process:** program running within a host  
**Client process:** process that initiates communication  
**Server process:** process that waits to be contacted
- applications wtih P2P have client and server process

## Sockets
- A **socket** is one endpoint (IP and port) of a two-way communication link between programs on a network.
  
<img src="./images/socket.png" width="500" height="auto">

- To receive messages, processes must have an **identifier**
- Host devices has a **unique 32-bit IP address** and a **port number** associated to process
  - HTTP server: port 80
  - mail server: port 25
- **Identifier** includes **both** the IP address and port number
- To send HTTP message to http://gaia.cs.umass.edu/ web server:
  - IP address: 128.119.245.12
  - Port number: 80

## Application-layer protocol defines
<img src="./images/d.png" width="550" height="auto">

### What transport service does an app need?
- **data integrity** - some apps require 100% file transfer
- **timing** - some apps require low delay (internet telephony, games)
- **throughput** - some apps require min throughput 
- **sercurity** - encryption, data integrity

## Uniform resource locator (URL)
`protocol://host-name[:port]/directory-path/resource`

- **protocol**: http, tfp, https, smtp
- **hostname**: DNS name, IP address
- **port**: defaults to protocol standard(http: 80, https: 443)
- **directory path**: file system
- **resource**: identifies resource

Example: `www.someschool.edu/someDept/pic.gif`

## HTTP overview
**HTTP: hypertext transfer protocol** 
- **client**: browser that requests,receives, (using HTTP protocol) and “displays” Web objects
- **server**: Web server sends (using HTTP protocol) objects in response to requests

<img src="./images/http.png" width="350" height="auto">

- Uses TCP
  - client initiates connection, server accepts, HTTP message exchanged
- HTTP is stateless
  - server maintains no info about previous requests
- type types of HTTP messgaes: **request, response**

### Types of HTTP requests
<img src="./images/crud.png" width="550" height="auto">

### HTTP response status codes
**200** OK
- request succeeded, requested object later in this message
  
**301 Moved Permanently**
- requested object moved

**400 Bad Request**
- request msg not understood by server

**404 Not Found**
- requested document not found on this server

### HTTP is all text
- A text-based header is easier for human beings to read and debug. Text-based headers are
also extensible.
- They are verbose (i.e., waste bandwidth) and harder to parse.
- makes protocol simple
- not the most efficient
  - "12345678" - 8 bytes
  - 12345678 - 4 bytes

## Maintaining user/server state: cookies
Web sites and client browser use **cookies** to maintain some state between transactions

<img src="./images/cookie.png" width="550" height="auto">

- authorisation
- shopping carts
- recommendations

**Cookies and Privacy**
- cookies permit sites to learn a lot about you on their site
- third party persistent cookies allow common identity to be tracket across multiple web sites

## Page Load Time (PLT)
Page Load Time (PLT) is an important metric
- from click (or typing url) until user sees page
- key measurement of web performance

Depends on many factors such as
- page content/structure,
- protocols involved and
- Network bandwidth and RTT

## Non-persistent HTTP (HTTP/1.0)
**Non-Persistent**: **One TCP connection** to fetch **one web resource** (connection then closed)
- downloading multiple objects requires multiple connections

<img src="./images/rtt.png" width="300" height="auto">

**RTT** (Round trip time): time for a small packet to travel from client to server and back

- one RTT to initiate TCP connection
- one RTT for HTTP request and first few bytes to return
- file transmission time

<img src="./images/nop.png" width="250" height="auto">

## Non-persistent HTTP/1.0 response time formula

**1 Object Time** = Connection($1RTT$) + File($1RTT$) + file transmission time

**N Objects Time** = N(Connection($1RTT$) + File($1RTT$) + file transmission time)

### Concurrent Request and Responses (Possible solution to slow PLT)
- Use multiple connections in parallel
- Does not necessarily maintain order of responses

**Downsides**
- Too much overhead (so many different connections to server at once)

## Persistent HTTP (HTTP/1.1)
- server leaves TCP connection open after sending response
- subsequent HTTP messages between same client/server are sent over the same TCP connection

**Persistent without pipelineing**
- client issues new request only when previous response has been received
- one RTT for each referenced object

**Persistent pipelineing**
- introduced in HTTP/1.1
- client sends requests as soon as it encounters a referenced object
- as little as one RTT for all the referenced objects

<img src="./images/1.1.png" width="450" height="auto">

<br>

**Better image to display persistent with pipelining**

<img src="./images/s.png" width="450" height="auto">

- bold line 1 - base index file
- bold lines 2, 3, 4 - objects on page

1 RTT for connection, 1 RTT for index page, 1 RTT of 3 objects

## Non-Persistent HTTP/1.1 response time formula
**Index page** = Connection($1RTT$) + index($1RTT$)

**Index page** + N objects = Connection($1RTT$) + index($1RTT$) + N(object($1RTT$))

## Persistent HTTP/1.1 response time formula
**Index page** = Connection($1RTT$) + index($1RTT$)

**Index page + N objects** = Connection($1RTT$) + index($1RTT$) + objects($1RTT$)

## Downsides of HTTP 1.1
- server responds in **FCFS**(first-come-first-served scheduling) to `GET` requests
- small object may have to wait for transmission behind large object resulting in HOL(head of line) blocking

<img src="./images/hol.png" width="500" height="auto">

## HTTP/2: mitigating HOL blocking
- transmission order of requested objects based on client-specified
object priority (not always FCFS)
- divide objects into frames, schedule frames to mitigate HOL blocking

<img src="./images/hol1.png" width="500" height="auto">

## Web caches: proxy server
Goal: satify client request without involving origin server

- user configures browser to point to a Web cache
- browser sends all HTTP requests to cache

```
if object in cache:
  cache returns cached object to client
else:
  cache requests object origin, then caches object then return
```

<img src="./images/cache.png" width="400" height="auto">

## Example: how caching improves speeds

<img src="./images/c1.png" width="425" height="auto">
<img src="./images/c2.png" width="425" height="auto">
<img src="./images/c3.png" width="425" height="auto">

**cache hit rate**: chance that the HTTP request is already stored in the local web cache

**LAN utilisation** = average data rate / LAN rate  
**Access link utilisation** = average data rate / access link rate

## Conditional `GET`: cache at client browser
Do not send object if cache has up-to-date cached version

- no object transmission delay
- lower link utilisation 

**cache**: specify date of cached copy in `HTTP` request  
- **If-modified-since: < date >**

**server**: response contains no object if cached copy is up-to-date:  
- **HTTP/1.0 304 Not Modified**

## Replication: improving HTTP 
Replicate popular Web site across many machines
- Spreads load on servers
- Places content closer to clients
- Helps when content isn’t cacheable

## CDN (Content Delivery Network): improving HTTP 
CDN: stores copies of content at CDN nodes
- Netflix stores copies of movies 

Subscriber requests content from CDN
- directed to nearby copy to retrieve content from

Caching and replication as a service, large-scale distributed storage infrastructure.

- Combination of (pull) client requests from cache and (push) cache requests from server
  - **Pull**: Direct result of clients’ requests
  - **Push**: Expectation of high access rate

## Electronic Mail
### User Agent (mail reader, Outlook, iPhone mail app)
- composing, editing, reading mail messages
- outgoing, incoming messages stored on server

### Mail Servers:
- **mailbox** contains incoming messages for user
- **message queue** of outgoing (to be sent) mail messages
- **SMTP protocol** between mail servers to send email messages
  - client: sending mail server
  - “server”: receiving mail server
  
<img src="./images/m.png" width="300" height="auto">

### Properties
- uses **TCP** to reliably transfer email message from **client** (mail server initiating connection) **to server, port 25**
- **direct transfer**: sending server (acting like client) to receiving server
- **Three phases** of transfer:
  - handshaking (greeting)
  - transfer of messages
  - closure
- command/response interaction (like HTTP)
  - commands: ASCII text
  - response: status code and phrase
- messages (header & body) must be in **7-bit ASCI**

### Comparison with HTTP
- **HTTP**: pull based (client request), **SMTP**: push based (server request)
- Both have **ASCII** command/response interaction, **status codes**
- **HTTP**: each object encapsulated in its **own response message**, **SMTP**: multiple objects sent in **multipart message**
- SMTP uses **persistent** connections
- SMTP requires message 7-bit ASCII

**Format**

<img src="./images/for.png" width="450" height="auto">

### Mail example:
<img src="./images/mail.png" width="450" height="auto">

### Mail access protocol
- **SMTP**: delivery/storage of e-mail messages to receiver’s server  
- **IMAP**(Internet Mail Access Protocol): Provides retrieval, deletion, folders of stored messages on server
- **HTTP**: provides web-based interface on top of STMP (to send), IMAP to retrieve e-mail messages
  - gmail, Hotmail, Yahoo! Mail, etc. 

- **Note:** If the **client is user a web-based email** client like gmail on web the email is transmitted from to the server using **HTTP/HTTPS**.

<img src="./images/ma.png" width="450" height="auto">

## DNS: Domain Name System
- Maps hostname to IP address (32 bit) translation
- Initially all host-address mappings were in a hosts.txt file
  
<img src="./images/dns.png" width="450" height="auto">

### Server Hierachy
  
**Top of hierarchy: Root servers**
- Location hardwired into other servers
- ICANN (Internet Corporation for Assigned Names and Numbers) manages root DNS domain
  
**Next Level: Top-level domain (TLD) servers**
- .com, .edu, etc. (several new TLDs introduced recently)
- Managed professionally

**Bottom Level: Authoritative DNS servers**
- Store the name-to-address mapping
- Maintained by the corresponding administrative authority

<img src="./images/hier.png" width="500" height="auto">

## Local DNS name servers
- Does not strictly belong to hierarchy
- Hosts learn about the local DNS server via a host configuration
protocol (DHCP)
- When host makes DNS query, query is sent to its local DNS server
  - local cache of recent name-to-address translation pairs 
  - acts as proxy, forwards query into hierarchy

## Iterated Query
- Implemented by Global DNS servers (the ones in hierachy)
  
<img src="./images/iter.png" width="550" height="auto">

## Recursive Query
- Implemented by Local DNS server
  
<img src="./images/recur.png" width="500" height="auto">

## Caching, Updating DNS Records
Once name server learns mapping, it **caches mapping**
- cache entries timeout (disappear) after some time (TTL)
- cached entries may be out -of -date
- Top Level Domain (TLD) servers typically cached in local name servers (root typically not visited)

## DNS Records
Distributed database storing **resource records (RR)**
- **RR** format: (name, value, type, ttl)
  
<img src="./images/record.png" width="450" height="auto">

- **A** records provide a mapping from hostname to IP address.
  - (smtp.gmail.com, 108.177.125.10, XXX, 2 days)
  - (ns1.google.com, 216.239.32.10, XXX, 2 days)
  - (ns2.google.com, 216.239.34.1, XXX, 2 days)
- **MX** refers to the mail server record. 
  - (gmail.com, smtp.gmail.com, XXX, 2 days)
- **NS** refers to a name server record which provides the name of the nameserver responsible for the hostname/domain.
  - (ns1.google.com, 216.239.32.10, XXX, 2 days)
  - (ns2.google.com, 216.239.34.1, XXX, 2 days)
- **CNAME** refers to a canonical name record for the hostname.

### DNS protocol messages
DNS **query** and **reply** have the same format

<img src="./images/p1.png" width="400" height="auto">
<img src="./images/p2.png" width="400" height="auto">

## Inserting into DNS Example
Register name **networkuptopia.com** at DNS registrar 
- provide names, IP addresses of authoritative name server (primary and
secondary)
- registrar inserts NS, A RRs into .com TLD server:
  - (networkutopia.com, dns1.networkutopia.com, NS)
  - (dns1.networkutopia.com, 212.212.212.1, A)

## DNS Reliability
- DNS servers are replicated (primary/secondary)
  - Name service available if at least one replica is up
- DNS uses port 53
- Usually, UDP used for queries
- Try alternate servers on timeout

## DNS Security
**DDOS**  
- Bombard root servers with traffic
  - not successful to date
  - local root servers cache IPs of Top level domain servers allowing bypass

**Redirect attacks**
- Man in the middle
  - intercept DNS queries
- DNS poisoning
  -  send bogus replies to DNS which caches

**Exploit DNS for DDoS**
- send queries with spoofed source address

## DNS Cache Poisoning
<img src="./images/poi.png" width="450" height="auto">

## Peer-peer architecture (P2P)
- no need for always-on server
- peers request service from other peers and provide servce in return to other peers
  - self scalability – new peers bring new service capacity
- peers are intermittently connected and change IP address
  
## Client Server: File distribution time formula
<img src="./images/time.png" width="450" height="auto">

**Server transmission**  
Must sequentially send (upload) **$N$** file copies:
- time to send one copy: $\frac{F}{u_s}$
- time to send N copies: $N\frac{F}{u_s}$

**Client: each client must download file copy**
- $d_{min}$ = minimum client download rate
- Slowest client download time: $\frac{F}{d_{min}}$ 

**Time to distribute file $F$ to $N$ clients using client-server**  

$D_{cs} \geq$ max{$N\frac{F}{u_s}, \frac{F}{d_{min}}$}

<img src="./images/cs.png" width="250" height="auto">

- $D_{cs}$ = time to distribute file (s)
- $N$ = Number of clients
- $F$ = File size (bits)
- $u_s$ = server upload speed (bits/s)
- $d_{min}$ = minimum client download speed (b/s)

## P2P: File distribution time formula
<img src="./images/time.png" width="450" height="auto">

**Server transmission**  
Must sequentially send (upload) one file copy:
- time to send one copy: $\frac{F}{u_s}$

**Client: each client must download file copy**
- $d_{min}$ = minimum client download rate
- Slowest client download time: $\frac{F}{d_{min}}$ 

**Time to distribute file $F$ to $N$ clients using P2P**  

**$D_{P2P} \geq$ max{ $\frac{F}{u_s}, \frac{F}{d_{min}}$, $\frac{NF}{u_s + \Sigma u_i}$ }**

<img src="./images/p2p.png" width="300" height="auto">

- $D_{P2P}$ = time to distribute file (s)
- $F$ = File size (bits)
- $u_s$ = server upload speed (bits/s)
- $d_{min}$ = minimum client download speed (b/s)
- $N$ = Number of clients
- $u_i$ = upload speed of $i$th client (b/s)

## Client-Server vs P2P time

<img src="./images/g.png" width="450" height="auto">

### Example: BitTorrent
- peers in torrent send/receive file chunks

<img src="./images/web.png" width="500" height="auto">

**Requesting chunks**

- At any given time, different peers have different subsets of file
- Peers ask fellow peers what chunks they have
- Peers request for missing chunks **rarest** first

**Sending chunks (tit-for-tat)**  
Peer sends chunks to four peers currently sending chunks at highest rate
- re-evaluate top 4 every 10 secs
- every 30 secs: randomly select another peer, starts sending chunks (even if peer is not uploading data)
  - "optimistic unchoke” this peer
  - newly chosen peer may join top 4

## Video Streaming
**Videos**: sequence of image displayed at constant rate  
**Image**: array of pixels (each pixel is a bit)

Solution: use redudancy (repeated elements) within the between images to decrease number of bits used

<img src="./images/vid.png" width="300" height="auto">

## DASH: Dynamic, Adaptive, Streaming over HTTP
**Server**

- divides video into multiple chunks
- each chunck stored, encoded at different rates
- **manifest file**: URL for different chunks

**Client**

- periodically measures server-to-client bandwidth
- consulting manifest, requests one chunk at a time

**Streaming Video = encoding + DASH + playout buffering**

<img src="./images/ne.png" width="450" height="auto">


# Transport Layer
## Transport services and Protocols
- **logical communication** between application processes running on different hosts
- **sender**: breaks applications messages into segments 
- **receiver**: reassembles segments into messages
- Protocols available: TCP, UDP

## Highlevel: TCP and UDP
**TCP:** Transmission Control Protocol
- reliable, **in-order delivery**
- congestion control
- flow control
- connection setup

**UDP:** User Datagram Protocol
- unreliable, unordered delivery
- faster than TCP (used for VOIP)
- no delay or bandwidth guarantees

## Multiplexing and Demultiplexing
**Multiplexing (Sender):** Combining data from multiple applications into one stream for transmission, with headers added to identify each data source.  
**Demultiplexing (Receiver):** Separating incoming data and directing it to the correct application based on header information.

<img src="./images/mudu.png" width="700" height="auto">

### UDP -  Connectionless demultiplexing
When host receives UDP segment:
- Contains destination **IP**and **port number**
- Checks **destination port number** in segment and directs UDP segment to **socket** with that port number.
- UDP datagrams with **same destination port** but different source IP will be directed to **same socket at host**.

<img src="./images/less.png" width="600" height="auto">

### TCP -  Connection demultiplexing
TCP socket identified by 4-tuple:
- source IP address
- source port number
- destination IP address
- destination port number

Demux: receiver uses all four values to direct segment to appropriate socket.

- The server has a welcoming (listening) socket, which is used to accept incoming client connections. 
- A new socket is opened for each connection (even if same port is specified unlike UDP).

**X = 80** in image below

<img src="./images/sock.png" width="400" height="auto">
<img src="./images/z.png" width="600" height="auto">

- UDP: demultiplexing using destination IP and port number
(only)
- TCP: demultiplexing using 4-tuple: source and destination IP
addresses, and port numbers

## UDP: User Datagram Protocol
Internet transport protocol with best-effort service so segments may be:
- lost
- delivered out-of-order to app

**Connectionless**
- **no handshaking** between sender and receiver (no RTT delay)
- no connection state at sender, receiver
- small header size
- no congestion control
  - UDP can still transport if network is congested
- each UDP segment handled indepdendently of others

**Applications that use UDP**
- DNS
- SNMP (network management)
- HTTP/3

If reliable transfer needed over UDP:
- add reliability **at application layer**
- add congestion control **at application layer**

### UDP: Transport Layer Actions
<img src="./images/send.png" width="500" height="auto">
<img src="./images/receive.png" width="550" height="auto">

### UDP segment format
<img src="./images/dia.png" width="500" height="auto">

### UDP Checksum
Detect errors (flipped bits) in transmitted segment
- Treat content of UDP segment as sequence of 16-bit integers and check **sum of transmitted = sum of received**

Transmitted: 5 + 6 = 11  
Received: 4 + 6 = 10  
11 $\neq$ 10, so there was a error. 

<img src="./images/add.png" width="500" height="auto">

### Checksum Example
<img src="./images/check.png" width="500" height="auto">

At the receiver, when adding all the values together the result should be a 16-bit sequence of **All 1s** (result of using 1's complement, adding the last two line in the image above). The receiver uses an `AND` gate so result is 1, otherwise there was an error (bit flip).

## Reliable data transfer
<img src="./images/rdt.png" width="700" height="auto">

## rdt 1.0 reliable transfer over a reliable channel
underlying channel perfectly reliable
- no bit errors
- no loss of packets
- no out of order delivery
  
<img src="./images/1.0.png" width="450" height="auto">

## rdt2.0: channel with bit errors
underlying channel may flip bits in packet
- **checksum** used to detect bit errors at receiver.

**How do we recover from detected errors?**
- **acknowledgements (ACK)**: receiver explicitly tells sender that packet received OK.
- **negative acknowledgements (NACK)**: receiver explicitly tells sender that packet had errors.
- sender retransmits packet on receipt of NACK

**STOP AND WAIT**: sender sends one packet, then waits for receiver response.

<img src="./images/2.0.png" width="450" height="auto">


### Flaw with rdt2.0
Both ACK/NACK can be corrupted. Sender retransmisted current packet if ACK/NACK is corrupted.

## rdt2.1 

**Sender**:
- Sequence number # added to each packet.
- Two sequence numbers: #0 or #1.
- must check if received ACK/NACK is corrupted.

**Receiver**:
- Must check if received packet is duplicated.
- Receiver does not know if its last ACK/NACK received OK at sender.

<img src="./images/2.1.png" width="450" height="auto">

## rdt2.2: a NACK-free protocol
same functionality as rdt2.1, using **ACKs only**
- instead of NACK, receiver sends ACK for last packet received OK
  - receiver must explicitly include seq# of packet being ACKed
- duplicate ACK at sender results in a retransmit current packet.
  
As we will see, TCP uses this approach to be NACK-free.

<img src="./images/2.2.png" width="450" height="auto">

## rdt3.0: channels with errors **and loss**
underlying channel can also lose packets (data, ACKs), not just bit flip errors.

**Solution**: 
Sender waits **“reasonable” amount of time** for ACK
- Automatic retransmit if no ACK received in this time.
- If pkt (or ACK) just delayed (not lost):
  - retransmission will be duplicate, seq#s handles this.

<img src="./images/3.0.png" width="500" height="auto">
<img src="./images/3.01.png" width="500" height="auto">

### Performance of rdt3.0 (stop and wait)
$U_{sender}$: utilisation – fraction of time sender busy sending

<img src="./images/y.png" width="500" height="auto">

<img src="./images/st.png" width="500" height="auto">

## Channel utilisation formula
$U_{sender} = x * \frac{\frac{L}{R}}{RTT + \frac{L}{R}}$  

<img src="./images/util.png" width="300" height="auto">

$x$ = windows size  
$L$ = length of packet (bits)  
$R$ = bandwidth (bits/sec)  
$RTT$ = round trip time (sec)

## rdt3.0: pipelined protocols operation
**pipelining**: sender allows multiple, “in-flight”, yet-to-be-acknowledged
packets
- range of sequence numbers must be increased
- buffering at sender and/or receiver

<img src="./images/inc.png" width="500" height="auto">

## Go-Back-N: sender
- Sender: window of up to N, consecutive transmitted but **unACKed** packets 
  
<img src="./images/gobackN.png" width="500" height="auto">

- **cumulative ACK**: ACK(n): ACKs all packets up to, including seq # n
  - on receiving ACK(n): move window forward to begin at n+1
- only maintains a **timer for oldest in-flight packet**
- timeout(n): retransmit packet n and all higher seq # packets in window

## Go-Back-N: receiver
- Receiver: window size of 1. 
- Always send ACK for packet with highest **in-order** seq# successfully received so far.
  - only need to remember `rcv_base` (represents the sequence # of the earliest byte that has not yet been acknowledged by the receiver)

- on receipt of out-of-order packet:
  - can discard (no buffer) or buffer: an implementation decision
  - re-ACK packet with highest **in-order** seq#

<img src="./images/rec.png" width="500" height="auto">

<img src="./images/go.png" width="500" height="auto">

- ACK number is the sequence number of the last in-order packet that has been correctly received.

## Selective repeat
- Receiver individually acknowledges all correctly received packets
  - buffers packets, as needed
- Individual timer for each unACKed packet within the sender’s window.
  - sender times-out/retransmits individually for unACKed packets
- sender window
  - N consecutive seq #s
  - limits seq #s of sent, unACKed packets
  
<img src="./images/asdf.png" width="550" height="auto">
<img src="./images/re.png" width="550" height="auto">

- ACK number is the sequence number of the last in-order packet that has been correctly received.
- When ACK2 arrives, since ACK3 already arrived before it the window becomes [4,5,6,7]

## Selective repeat problem
<img src="./images/dil.png" width="550" height="auto">

a) No issues since receiver recognises **pk3 is lost** and new pk0 is buffered (since it is in the receivers current window) until **pk3** is retransmitted and received.

b) Issue because the receiver window is already contains **new pk0**, however the **old pk0** is retransmitted since it there was no **ack1 was lost**.

### Solution to selective repeat problem
Sender window size $\leq \frac{1}{2}$ sequence number space. The maximum sequence number formula: $2^n / 2$, where $n$ = num bits

- The sequence number space is 4 (0, 1, 2, 3). So window size $\leq$ 2

## Connection-oriented transport: TCP

## TCP Header
<img src="./images/tcph.png" width="550" height="auto">

- Sequence number can be up to 32 bits, which represents up to $2^{32}$ numbers $\approx$ 4 billion 
- **HdrLen = Header Length** (required since header length not fixed, but rarely changes)
  - Min length = 20 bytes (most common), Max length = 60 bytes
- **Checksum**: computer over header and data

## TCP Sequence number are byte offsets
<img src="./images/stream.png" width="525" height="auto">
<img src="./images/sg.png" width="525" height="auto">

### TCP Maximum Segment size
<img src="./images/size.png" width="400" height="auto">

**MSS = MTU - 20 (IP header) - 20 (TCP header)** (ONLY TCP payload, no TCP header, no IP header)

- IP Packet
  - **IP Packet = IP header + IP segment/payload (TCP Packet)**
  - No bigger than Maximum Transmission Unit (**MTU**) of link layer
  - Example: 1500 bytes for Ethernet
- TCP packet
  - **TCP Packet = TCP Header + TCP segment/payload (Application layer data)**
  - 20 bytes $\leq$ TCP header $\leq$ 60 bytes (generally is 20 bytes)
- TCP segment/payload
  - No more than maximum segment size (**MSS**) bytes
  - Up to 1460 consecutive bytes from the stream

### TCP Sequence Numbers
**ISN = Initial sequence number** (not 0)

- Sequence number = ISN + k bytes
- ACK sequence number = Sequence number + TCP Data Length (not header)
  
<img src="./images/nu.png" width="500" height="auto">

### Why chose random ISN
-  Avoids ambiguity with back-to-back connections between same end-points.
-  Potential security issue if the ISN is known.

## Cumulative Sequence Acknowledgements
ACK number represents the next expected byte (or packet) in the sequence. The ACK number is the highest in-order byte sequence number + 1.

**Scenario 1**

<img src="./images/cumul.png" width="600" height="auto">

**Scenario 2**

<img src="./images/s2.png" width="600" height="auto">

200 - 249 and 250 - 299 are buffered until 150 - 199 is received.

### Tutorial Example
<img src="./images/tut.png" width="600" height="auto">

## Piggybacking (both sides send and transmit)
Both client and server send and receive data.

<img src="./images/pig.png" width="250" height="auto">
<img src="./images/ac.png" width="400" height="auto">
<img src="./images/pig2.png" width="400" height="auto">

**Binary conversions**
- 1 KB = 1024 b
- 1 MB = 1024 KB
- 1 kbps (kilo bit per second) = 1000 bps (bits per second)

## TCP RTT Timeout Formulas
**SampleRTT** = measured time from segment transmission until ACK
- this will vary, so instead we want an estimated RTT 

**EstimatedRTT = (1 - $\alpha$) $\times$ EstimatedRTT(k) + $\alpha$ $\times$ SampleRTT**

- exponential weighted moving average (EWMA)
- influcent of past sample decreases exponentially faster
- typical value $\alpha$ = 0.125

**DevRTT = (1 - $\beta$) $\times$ DevRTT(k) + $\beta$ $\times$ |SampleRTT(k) - EstimatedRTT(k)|**
- EWMA of SampleRTT deviation from EstimatedRTT
- typically, $\beta$ = 0.25 

**TimeoutInterval = EstimatedRTT + 4$\times$DevRTT**

### Exclude retransmissions in RTT computation
- Sender cannot differentiate between original ACK and retransmission ACK
- **RTT = Final ACK - Original transmission**

## TCP rdt
- TCP uses a combination of go-back-N and selective repeat
- TCP uses a single timer for the oldest unacknowledged segment.
- The receiver employs a delayed ACK mechanism.
- Retransmit packets upon timer timeout events
- TCP uses cumulative acknowledgements
- Sender retransmits a segment when it receives triple duplicate ACKs 

<img src="./images/tcprdt.png" width="500" height="auto">

### Delayed ACKs
<img src="./images/dack.png" width="500" height="auto">

### Retransmission scenarios
<img src="./images/s1.png" width="500" height="auto">
<img src="./images/s3.png" width="500" height="auto">

ACK = 92 in last image

## TCP Fast retransmit
<img src="./images/fret.png" width="500" height="auto">
 
Note: 3 additionaly so 4th ACK.

## Flow Control
Receiver controls sender, so sender won’t overflow receiver’s buffer by transmitting too much, too fast. (Fast computer does not want to overwhelem slow computer like a phone).

In TCP, window size is NOT fixed, it is **adaptive**, it controls the number of packets that can be sent out without waiting for an ACK. Adjusting the window size helps with flow control. 

<img src="./images/flow.png" width="550" height="auto">

**rwnd** = receiver window size

<img src="./images/bruv.png" width="225" height="auto">

If **rwnd = 0**, then
- Sender would stop sending data
- Eventually the receive buffer would have space when the application process reads some bytes

Sender keeps sending TCP segments with one data byte to the receiver
- These segments are dropped but acknowledged by the receiver
with a zero-window size
- Eventually when the buffer empties, non-zero window is advertised

## Connection Management
Before exchanging data, sender/receiver “handshake”:
- agree to establish connection (each knowing the other willing to establish connection)
- agree on connection parameters (starting seq numbers)

## TCP-3 way Handshake
<img src="./images/3way.png" width="700" height="auto">

**Important:** SYN and FIN flag bits consume 1 sequence number (acts as 1 byte)

### What happens if the SYN gets lost?
 Suppose the SYN packet gets lost
- Packet is lost inside the network, 
- Server discards the packet (e.g., it’s too busy) 
 
Eventually, no SYN-ACK arrives
- Sender sets a timer and waits for the SYN-ACK
- … and retransmits the SYN if needed

## Types of Terminations

### One at a time termination
<img src="./images/normal.png" width="600" height="auto">

Individual FINs and ACKs

### Both together termination
<img src="./images/both.png" width="600" height="auto">

FIN + ACK together from the server

### Simultaneous termination
<img src="./images/sim.png" width="600" height="auto">

FINs sent at the exact same time

## Abrupt Termination
When the client/server suddenly crashes you need to send a **RST** (Reset) flag.
<img src="./images/rst.png" width="600" height="auto">

## Congestion Control
Too many sources sending too much data too fast for network to handle. (Two fast super computers sending data to each other but the network is congested)

### Cost of congestion
<img src="./images/con.png" width="500" height="auto">

- Throughput slows down as load increases. 
- Delay increases exponentially as loads increase.

### Approaches towards congestion control
**End-end congestion control**  
Design algorithms that can infer the congestion level of the network which dynamically controls the rate of data injected into the network.

**Network-assisted**  
Monitoring tools inside router to sense buffer size and communicate with all devices if the router is congested. Problem with this is notifying the senders of the buffer size (millions of senders).

<img src="./images/br.png" width="500" height="auto">

## TCP’s Approach to congestion control
**Vary window size to control sending rate**
- TCP connection maintains a window and controls the number of in-flight packets.
- TCP sending rate: send **cwnd** (congestion window) bytes, wait for RTT for ACKs, then send more bytes.
  
Rate $\approx \frac{cwnd}{RTT}$ bytes/sec

## Flow control vs Congestion controls
Flow control window: **Advertised / Receive Window (RWND)**
- How many bytes can be sent without overflowing receiver’s buffers
- Determined by the receiver and reported to the sender

Congestion Window: **CWND**
- How many bytes can be sent without overflowing routers
- Computed by the sender using congestion control algorithm

Sender-side window = **minimum {CWND, RWND}**
- Assume for this discussion that RWND >> CWND

### CWND
CWND has units in bytes, however for purpose of lecture, the units used is MSS (Max segment size, the amount of payload data in TCP).

## Congestion Detection

**Duplicate ACKs: isolated loss**
- dup ACKs indicate network capable of delivering some segments
  
This means packets subsequent packets after the lost packet has been delivered successfully.  Congestion status is the **network is midly congested**.
 
**Timeout: much more serious**
- Not enough dup ACKs
- Must have suffered several losses
  
Subsequent packets are also lost. Congestion status is **seriously congested**.

## Rate adjustment
Basic structure:
- Upon receipt of ACK (of new data): increase rate
- Upon detection of loss: decrease rate
  
How we increase/decrease the rate depends on the phase of congestion control we’re in:
- Discovering available bottleneck bandwidth vs.
- Adjusting to bandwidth variations

## TCP Slow Start (Bandwidth discovery) 
<img src="./images/slow.png" width="500" height="auto">

## AIMD (Additive increase multiplicative decrease)
<img src="./images/aimd.png" width="500" height="auto">

- Successful = linear increase
- Unsuccessful = factored decrease

## Slow Start Threshold (ssthresh)
- Introduce a “slow start threshold” **(ssthresh)**
  - Initialised to a large value (value on graph when expoential ends)
- Convert from Slow start to AIMD when **CWND = ssthresh**
  - On loss, **ssthresh = CWND/2**

<img src="./images/saw.png" width="500" height="auto">

## Events that cause CWND to change
<img src="./images/sh.png" width="500" height="auto">

### ACK
```
If CWND < ssthresh
  CWND += 1 (Slow start phase)
Else
  CWND = CWND + 1/CWND (Congestion Avoidance phase)
```

### 3 dupACK
If dupACKcount = 3 (fast retransmit)
- ssthresh = CWND/2
- CWND = CWND/2

### Timeout
On Timeout
- ssthresh = CWND/2
- CWND = 1

## TCP Flavours
<img src="./images/flv.png" width="500" height="auto">

<br>

**TCP-Tahoe**  
Goes back to slow start on either triple dupACK and timeout.

**TCP-Reno**  
Goes back to slow start when only when on timeout or when cwnd = 1. cwnd is halved if triple dupACK.

# Network Layer
All packets use a common **Internet Protocol**

**Note:** In IP, packets are called datagrams

## Routers
- examines header fields in all IP datagrams passing through it
- moves datagrams from input ports to output ports to transfer datagrams along end-end path

<img src="./images/r and f.png" width="500" height="auto">

### Data Plane vs Control Plane

**Data Plane**
- local, per-router function
- determines how datagram arriving on router input port is forwarded to router output port

**Control Plane**  
Network-wide logic
- determines how datagram is routed among routers along end- end path from source host to
destination host
- two control-plane approaches:
  - traditional routing algorithms: implemented in routers
  - software-defined networking (SDN): implemented in (remote) servers

### Best effort service model
**No guarantees** on:  
- successful datagram delivery to destination
- timing or order of delivery
- bandwidth available to end-end flow

**Reflections on best effort**

- **simplicity of mechanism** has allowed Internet to be widely deployed adopted
- sufficient **provisioning of bandwidth** allows performance of real-time applications to be “good enough”. 
- **replicated, application-layer distributed services** (datacenters, content distribution networks) connecting close to clients’ networks, allow
services to be provided from multiple locations
- congestion control of “elastic” services helps

### IP Datagram Format
<img src="./images/ipformat.png" width="450" height="auto">

**Version number (4 bits)**
- Indicates the version of the IP protocol
- Necessary to know what other fields to expect
- Typically, “4” for IPv4 or "6" for IPv6

**Header length (4 bits)**
- Text based number that counts the words in the header
- Typically, “5”, this means 5 32-bit words, so 5 * 4 = 20 bytes.
- Can be more when IP **options** are used

**Total length (16 bits)**
- Number of bytes in the packet
- Maximum size is 65,535 bytes (216 -1)
- … though link layer protocols may impose smaller limits

**Protocol (8-bit)**
- Identifies the **higher-level protocol**
– Important for **demultiplexing** at receiving host

<img src="./images/pro.png" width="450" height="auto">

## Potential Problems with IP
<img src="./images/arrer.png" width="450" height="auto">

### Preventing Loops (TTL) 
Forwarding loops cause packets to cycle for a long time
- As these accumulate, eventually consume all capacity

<img src="./images/fwd.png" width="450" height="auto">

**Solution**  
Time-to-Live (TTL) Field (8 bits) 
- **Decremented at each ho**p, packet discarded if reaches 0. 
- “time exceeded” message is sent to the source.
- Recommended default value is 64.

### Header Corruption (Checksum)
**Checksum (16 bits)**
- If not correct, router discards packets.
- **Only computed over packet header** (payload carries TCP/UDP data which is already checked), method is same as UDP/TCP checksum.
- Recalculated at each router, since TTL changes as each router.

### IP fragmentation, reassembly
<img src="./images/frag.png" width="300" height="auto">

Network links have **MTU** (max transfer unit)
- different link types, different MTUs

Large IP datagram divided (“fragmented”)
- one datagram becomes several datagrams, to be reassembled at final destination.
- IP header bits used to identify, order related fragments.


<img src="./images/rem.png" width="550" height="auto">

Top datagram is 4000 bytes > 1500 bytes, so it must be split into 3 fragments. 
- ID (ID is circular, since there is a fixed max size).
  - 100, 101, 102 ... 100. 
- MF flag (more fragment) indicating the number of remaining fragments for this segment. 
- Offset the number of **8 bytes** (saves number of bits used per fragment) from the start this fragment contains. 
  - Offset = 2 means 2 * 8 = 16 bytes from start.
  - 2nd packet has offset **(1500 - 20) / 8 = 185**
  - If not exactly divisible by 8, then use floor() function
  <img src="./images/floor.png" width="450" height="auto">

### Fragments of fragments
<img src="./images/fof.png" width="550" height="auto">

If fragment 3 is split into 2 more fragments A and B, then the MF flag of A would be 1 and MF flag of B would be 0. Since 0 indicates last fragment. 

## Path MTU Discovery procedure
<img src="./images/proc.png" width="550" height="auto">

Find the minimum MTU, then set all packets to be <= this value.

## Special Handling
<img src="./images/sp.png" width="450" height="auto">

**Type of Service (8 bits)**
- Allow packets to be treated differently based on needs
  - low delay for audio, high bandwidth for bulk transfer
- Has been redefined several times
- **Not widely used**

### IP Datagram Format summary
<img src="./images/su.png" width="550" height="auto">

## IPv4 Addressing
**IP address**s: 32-bit identifier associated with each host or router interface

- **interface**: connection between host/router and physical link
  - router’s typically have multiple interfaces
  - host typically has one or two
interfaces (e.g., wired Ethernet, wireless 802.11)

<img src="./images/addy.png" width="400" height="auto">

## Subnets
Device interfaces that can physically reach each other without passing through an
intervening router.

- subnet part: devices in same subnet have common high order bits
- host part: remaining low order bits

<img src="./images/sub.png" width="500" height="auto">

## Network Mask
<img src="./images/mask.png" width="650" height="auto">

255.255.255.0 = 11111111.11111111.11111111.00000000

when you AND this with anything the last byte with always be 0.

## History of IP

### Original Internet Addresses
Assumed 256 networks were more than enough!
- First eight bits: network address (/8)
- Last 24 bits: host address, ~16.7 million

### Class-ful Addresses
<img src="./images/ful.png" width="550" height="auto">

## Subnetting for Classful Addresses
Subnetting is the process of dividing the class A, B or C network into more manageable chunks that are suited to your network’s size and structure.

- Extends the point where the 1’s of Mask stop and 0’s start
- Sacrificing some host ID bits to gain Network ID bits
- Subnetting allows 3 levels of hierarchy: **netid, subnetid, hostid**

<img src="./images/classb.png" width="550" height="auto">

- 141.14 is used to identify the organisation or netid.
- 141.14.x is used to identify the subnet of the network.
- 141.14.x.y is used to identify the host in a subnet x. 

### Designing a subnet
<img src="./images/des.png" width="500" height="auto">

6 subnets required, meanining 3 bits must be allocated to the subnetid. Therefore the mask must inlcude 3 additional 1's: 

255.255.255.224 = 11111111.11111111.11111111.11100000

The remaining 5 0's are the hostid for each subnet. In this case 2^5 = 32 per subnet.

<img src="./images/2^5.png" width="500" height="auto">

- 1st subnet: 201.70.64.0 - 201.70.64.31  
- 2nd subnet: 201.70.64.32 - 201.70.64.63 
- 3rd subnet: 201.70.64.64 - 201.70.64.95
- 4th subnet: 201.70.64.96 - 201.70.64.127
- 5th subnet: 201.70.64.128 - 201.70.64.159
- 6th subnet: 201.70.64.160 - 201.70.64.191

## Subnetting for Classless Addresses: CIDR
**CIDR: Classless InterDomain Routing**
- network portion of address of arbitrary length
- address format: **a.b.c.d/x**, where x is number of bits in network (netid) portion of address
  
<img src="./images/net.png" width="500" height="auto">

**Calculate the number of addresses and range of addresses**  
x = 23  
32 - 23 = 9
2^9 = **512 addresses** (510 usable, as generall 0 and 1 are not allocated)

**Range**: 200.23.16.0 - 200.23.17.255

<img src="./images/ip1.png" width="375" height="auto">
<img src="./images/ip2.png" width="375" height="auto">
<img src="./images/ip3.png" width="375" height="auto">
<img src="./images/ip4.png" width="375" height="auto">

## DHCP: Dynamic Host Configuration Protocol
Goal: Host dynamically obtains IP address from network server when it “joins” network

- host broadcasts DHCP discover msg [optional] 
  - dest ip: **255.255.255.255.255** or **11111111.11111111.11111111.11111111**
  - goes to every machine in network
- DHCP server responds with DHCP offer msg [optional] 
  - dest ip: **255.255.255.255.255** or **11111111.11111111.11111111.11111111**
  - goes to every machine in network
- host requests IP address: DHCP request msg
- DHCP server sends address: DHCP ack msg

<img src="./images/dhcp.png" width="550" height="auto">

### DHCP client-server scenario
<img src="./images/dhcp1.png" width="550" height="auto">
<img src="./images/dhcp2.png" width="550" height="auto">

### How do ISP's get IP addresses
ISP's buy IP addresses from ICANN: Internet Corporation for Assigned Names and Numbers

Organisations then get allocated a portion of its provider ISP’s address space

<img src="./images/isp.png" width="500" height="auto">
<img src="./images/as.png" width="450" height="auto">

### Longest prefix matching
When looking for forwarding table entry for given destination address, use longest address prefix that matches destination address.

<img src="./images/lpm.png" width="500" height="auto">

- DA: 11001000 00010111 00010110 10100001 matches link interface **0**
- DA: 11001000 00010111 00011000 10101010 matches link interface **1, 2**. Since 1 has a longer prefix, then interface **1** is chosen to send the datagrams too.

### Private Addresses
Defined in RFC 1918:
- 10.0.0.0/8 (16,777,216 hosts)
- 172.16.0.0/12 (1,048,576 hosts)
- 192.168.0.0/16 (65536 hosts)

These addresses cannot be routed
- Anyone can use them in a private network
- Typically used for NAT

## NAT: network address Transation
All devices in local network share just one IPv4 address as far as outside world is concerned.

<img src="./images/nat.png" width="550" height="auto">

- all devices in local network have 32-bit addresses in a “private” IP address space (10/8, 172.16/12, 192.168/16 prefixes) that can only be used in local network.

**Advantages:**
- just one IP address needed from provider ISP for all devices
- can change addresses of host in local network without notifying
outside world
- can change ISP without changing addresses of devices in local
network
- security: devices inside local net not directly addressable, visible
by outside world

### NAT: implementation
- **outgoing datagrams**: replace (source IP address, port number) of every outgoing datagram to (NAT IP address, new port number)
  - remote clients/servers will respond using (NAT IP address, new port num) as destination address
- **incoming datagrams**: replace (NAT IP address, new port #) in destination fields of every incoming datagram with corresponding (source IP address, port #) stored in NAT table

<img src="./images/nat2.png" width="600" height="auto">

### NAT: Practical Issues
- NAT modifies port num and IP address
  - Requires recalculation of TCP and IP checksum
- Some applications embed IP address or port numbers in their message payloads
- If applications change port numbers periodically, the NAT must be aware of this

### NAT traversal problem
<img src="./images/sol1.png" width="450" height="auto">
<img src="./images/sol2.png" width="450" height="auto">
<img src="./images/sol3.png" width="450" height="auto">

## Routing protocols 
Determine “good” paths (equivalently, routes), from sending hosts to receiving host, through network of routers.
- **path**: sequence of routers packets traverse from given initial source host to final destination host

### Types of internet routing
**intra-domain** routing protocol that establishes routes within its domain.
- Link State e.g., Open Shortest Path First (OSPF)
- Distance Vector e.g., Routing Information Protocol (RIP)

**inter-domain** routing protocol that establishes routes between domains
- Path Vector e.g., Border Gateway Protocol (BGP)

## Link state routing
### Each node maintains its local “link state” (LS)
- a list of its directly attached links and their costs

<img src="./images/ls1.png" width="450" height="auto">
  
### Each node floods its local link state
- on receiving a new LS message, a router forwards the message to all its neighbors other than the one it received the message from.

<img src="./images/ls2.png" width="450" height="auto">

### Flooding Link State Advertisement (LSA)
- A neighbouring router forwards out on all links except incoming
- Keep a copy locally, don’t forward previously-seen LSAs

Uses acknowledgements and retransmissions, sequence numbers, time-to-live for each packet to prevent errors.

### Eventually, each node learns the entire network topology
- Can use Dijkstra’s to compute the shortest paths between nodes

<img src="./images/ls3.png" width="450" height="auto">

**Note: Routers do not know when the network is complete**

## Dijkstra’s link-state routing algorithm
<img src="./images/dij.png" width="500" height="auto">
<img src="./images/dij2.png" width="500" height="auto">

### Establishing routing table using Dijkstra's
<img src="./images/dij3.png" width="500" height="auto">

1. Flooding to establish graph structure
2. Dijkstra's algo to get the min span tree
3. Use min span tree to get forwarding table

### Dijkstra's algo: changing cost values
When link costs depend on traffic volume, route oscillations possible.

**NOTE:** TRAFFIC IS NOT CHANGING, BUT COSTS OF PATH ARE SO ROUTES ARE CHANGING

<img src="./images/dij4.png" width="700" height="auto">

## Distance vector algorithm
Uses Bellman-Ford equation (dp)

$D_x(y) = min_v{c_{x,v} + D_v(y)}$

- From time-to-time, each node sends its own distance vector estimate
to neighbors

**each node:**
- wait for (change in local link cost or DV from neighbor)
- recompute DV estimates using DV received from neighbor
- if DV to any destination has changed, notify neighbors

### Problems with Distance Vector
- **Convergence** is the time during which all routers come to an agreement about the best paths through the internetwork
- Slow convergence/count to infinity (in practice max limit is imposed)

Example: A-B-C

If the link to B-C breaks and B has not send out its updated table, then A will advertise to B that it has a path to C, however this is not true since the path requires the B-C route. 

**Count to infinity Solutions**
- **Split Horizon**: Prevent a router to send a route back to the neighbour from which it learnt the path. 
  - Prevents A from sending C route to B.
- **Poison Reverse**: When advertising routes back to neighbour from which it was learnt, then the cost should be infinite (agreed upon large value).
  - A tells B its distance to C is infinite. 
- **Triggered Update**: Immediately send updates about changes in routing table (broken link) rather than waiting for interval update
- **Maximum cost value**: 16. However, max cost value can only be 15, max 15 routers in a row.

<img src="./images/dv.png" width="500" height="auto">

## Difference between Link State (LS) and Distance Vector (DV) algorithms
- LS: Requires state of all the routers
- DV: Requires state of only neighbours

### Message complexity
- LS: n routers, $O(n^2)$ messages sent
- DV: exchange between neighbors, convergence time varies

### Speed of convergence
- LS: $O(n^2)$ algorithm, $O(n^2)$ messages
  - may have oscillations
- DV: convergence time varies 
  - may have routing loops
  - count-to-infinity problem

## ICMP: Internet Control Message Protocol
Used by hosts & routers to communicate network level information.
- Between Transport and IP layer
  - ICMP messages carried in IP datagrams

<img src="./images/icmp.png" width="350" height="auto">

# Data Link Layer
Link layer has responsibility of transferring datagram from one node to physically adjacent node over a link.

- Link layer implemented in network interface card (NIC) or on a chip

## Parity checking
### Single bit parity:
- Detects single bit errors
- Does not detect two bit errors
- **even/odd parity:** add a parity bit such that there are an even/odd number of 1's

<img src="./images/sin.png" width="300" height="auto">

### two-dimensional bit parity:
- Detect and correct single bit errors
- Organise bits into a matrix and for each row/column use **single bit parity**
  - Similar to a two-way table
  - Cannot detect when bits in a square all error

<img src="./images/par.png" width="300" height="auto">
<img src="./images/pa.png" width="500" height="auto">

## Cyclic Redundancy Check (CRC)
In practice bit errors occur in bursts.

CRC is a more powerful error-detection coding that can detect burst errors.

- $D$: data bits 
- $G$: bit pattern 
- $r$: CRC bits, #$G - 1$ 
- $R$: remainder, ($D *2^r$) / $G$

We have data $D$ and known value $G$. Begin by dividing $D$ by $G$ to get remainder $R$ that has $r$ bits. Append the remainder $R$ to $D$, giving $<D,R>$, such that $<D,R>$ exactly divisible by $G$ (mod 2). 

On the receiver side, take $<D,R>$ % $G$ (mod 2) and if not exactly 0, then there was an error.

**Sender side**

<img src="./images/sender.png" width="500" height="auto">

**Receiver side**

<img src="./images/receiver.png" width="500" height="auto">

## Multiple Access Channel (MAC) Protocols
channel partitioning
- divide channel into smaller “pieces” (time slots, frequency, code)
- allocate piece to node for exclusive use
  
random access
- channel not divided, allow collisions
- “recover” from collisions
  
“taking turns”
- nodes take turns, but nodes with more to send can take longer turns

### TDMA: time division multiple access
Each node gets fixed short length (packet transmission time) slot for them to send data in rounds. 
- If there is a rate R and N nodes, then bandwidth for all users is R / N, even if some users  are idle (bands 2,5,6 in example).

<img src="./images/tdma.png" width="500" height="auto">

### FDMA: frequency division multiple access
Each node is assigned a fixed frequency band and all nodes can send simultaneously. 
- If there is a rate R and N nodes, then bandwidth for all users is R / N, even if some users  are idle (bands 2,5,6 in example).

<img src="./images/fdma.png" width="500" height="auto">

## Random access protocols
When node has packet to send transmit at full channel data rate R.

### Slotted ALOHA
- Time is divdied into equal size slots (time to transmit 1 frame)
- Nodes attempts to transmit frame at slot beginning
- Efficiency: 37%

**Collisions**
- if not collision: node can send new frame in next slot
- if collision: retrasmit frame in subsequent frames with a probability $p$ until success.

<img src="./images/slot.png" width="500" height="auto">

### Pure ALOHA
Transmit frame when it arrives.

**Collisions**
- Collision probability increases significantly
- Efficiency: 18%

<img src="./images/pure.png" width="500" height="auto">

### CSMA (carrier sense multiple access)
Simple CSMA: listen before transmit:
- if channel idle: transmit entire frame
- if channel busy: defer transmission

**Collisions**
- Collisions can still occur due to propogation delay.

### CSMA/CD (carrier sense multiple access with collision detection)
- Collisions detected within short time and transmissions aborted immediately, reducing channel wastage.
- After aborting, enter binary (exponential backoff)
  - after mth collision choose K at random from {0, 1, 2, ... 2^m - 1} and wait K time before next transmission.
- Efficiency: better performance than ALOHA: and simple, cheap, decentralized.